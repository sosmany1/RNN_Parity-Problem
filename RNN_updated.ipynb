{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_updated.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sosmany1/RNN_Parity-Problem/blob/master/RNN_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67UO1Uma-Pcu",
        "colab_type": "code",
        "outputId": "bc925d64-0543-46f1-a219-1e67eb2418c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17418
        }
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "\n",
        "num_epochs = 1000 \n",
        "total_series_length = 100\n",
        "state_size = 20 \n",
        "num_classes = 1 \n",
        "batch_size = 100 \n",
        "_learning_rate = 1e-1\n",
        "\n",
        "        \n",
        "def generateData():\n",
        "    x = 1.0-2*(np.random.randn(batch_size,total_series_length) < 0).astype(np.float32) \n",
        "    y = np.zeros((batch_size,total_series_length),np.float32) \n",
        "    for i in range(total_series_length):\n",
        "      y[:, i] = np.prod(x[:,0:(i+1)],axis=1)\n",
        "        \n",
        "    x = x.reshape((batch_size, -1))  \n",
        "    y = y.reshape((batch_size, -1))\n",
        "    return x, y\n",
        "\n",
        "batchX_placeholder = tf.placeholder(tf.float32, [batch_size, total_series_length]) \n",
        "batchY_placeholder = tf.placeholder(tf.float32, [batch_size, total_series_length]) \n",
        "\n",
        "inputs_series = tf.unstack(value=batchX_placeholder, axis=1, num=total_series_length) \n",
        "labels_series = tf.unstack(value=batchY_placeholder, axis=1, num=total_series_length) \n",
        "\n",
        "inputs_series = [tf.expand_dims(current_input,axis=1) for current_input in inputs_series]\n",
        "labels_series = [tf.expand_dims(current_label, axis=1) for current_label in labels_series]\n",
        "\n",
        "W = tf.Variable(tf.truncated_normal([2, state_size], stddev=1.0 / math.sqrt(float(2))), name='weights1')\n",
        "b = tf.Variable(tf.zeros([state_size]),name='biases1')\n",
        "\n",
        "W2 = tf.Variable(tf.truncated_normal([state_size, 1], stddev=1.0 / math.sqrt(float(state_size))), name='weights2')\n",
        "b2 = tf.Variable(tf.zeros([1]),name='biases2')\n",
        "\n",
        "\n",
        "prev_logit = tf.ones([batch_size, 1])\n",
        "states_series = []\n",
        "logits_series = []\n",
        "for current_input in inputs_series:\n",
        "  \n",
        "    current_input = tf.reshape(current_input, [batch_size, 1])\n",
        "    prev_logit = tf.reshape(prev_logit, [batch_size, 1])\n",
        "    input_and_state_concatenated = tf.concat([current_input, prev_logit],1) \n",
        "    \n",
        "    next_state = tf.nn.relu(tf.matmul(input_and_state_concatenated, W) + b)  \n",
        "    states_series.append(next_state)    \n",
        "    \n",
        "    prev_logit = tf.matmul(next_state, W2) + b2 \n",
        "    logits_series.append(prev_logit)\n",
        "\n",
        "\n",
        "losses = [(tf.reduce_mean(tf.nn.relu(1.0 - logits*labels))) for logits, labels in zip(logits_series,labels_series) ]  \n",
        "total_loss = tf.reduce_mean(losses)\n",
        "\n",
        "train_step = tf.train.GradientDescentOptimizer(learning_rate=_learning_rate).minimize(total_loss)\n",
        "\n",
        "accuracy = tf.reduce_mean(tf.cast(labels_series[-1]*logits_series[-1]>0,tf.float32))\n",
        "\n",
        "  \n",
        "init_op = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init_op)\n",
        "    plt.ion()#\n",
        "    plt.figure()#\n",
        "    plt.show()#\n",
        "    loss_list = []#\n",
        "    accuracy_list = []\n",
        "    for epoch_idx in range(num_epochs):\n",
        "      x,y = generateData()\n",
        "      _total_loss, _,_acc = sess.run(\n",
        "          [total_loss, train_step, accuracy],\n",
        "          feed_dict={\n",
        "              batchX_placeholder:x,\n",
        "              batchY_placeholder:y\n",
        "          })\n",
        "      loss_list.append(_total_loss)\n",
        "      accuracy_list.append(_acc)\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.plot(loss_list)\n",
        "      plt.subplot(1, 2, 2)\n",
        "      plt.plot(accuracy_list)\n",
        "\n",
        "      #print(\"Step\",epoch_idx, \"Accuracy Last Time Step\", _acc)\n",
        "      print(\"Loss\",_total_loss, \"Accuracy Last Time Step\", _acc)\n",
        "    #test on new data\n",
        "    #x,y = generateData()\n",
        "    #_total_loss, _acc = sess.run(\n",
        "    #    [total_loss, accuracy],\n",
        "    #    feed_dict={\n",
        "    #        batchX_placeholder:x,\n",
        "    #        batchY_placeholder:y\n",
        "    #     })\n",
        "    #print(\"Testing set Loss\",_total_loss, \"Accuracy Last Time Step\", _acc)\n",
        "plt.ioff()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fef53f764a8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss 0.9993611 Accuracy Last Time Step 0.43\n",
            "Loss 1.0008513 Accuracy Last Time Step 0.46\n",
            "Loss 0.99922395 Accuracy Last Time Step 0.48\n",
            "Loss 1.0002291 Accuracy Last Time Step 0.46\n",
            "Loss 0.99816734 Accuracy Last Time Step 0.46\n",
            "Loss 1.0001124 Accuracy Last Time Step 0.53\n",
            "Loss 0.9985367 Accuracy Last Time Step 0.55\n",
            "Loss 0.9980092 Accuracy Last Time Step 0.5\n",
            "Loss 0.99904037 Accuracy Last Time Step 0.48\n",
            "Loss 1.0003138 Accuracy Last Time Step 0.46\n",
            "Loss 0.9995564 Accuracy Last Time Step 0.49\n",
            "Loss 0.9998002 Accuracy Last Time Step 0.52\n",
            "Loss 0.999916 Accuracy Last Time Step 0.53\n",
            "Loss 0.99856097 Accuracy Last Time Step 0.55\n",
            "Loss "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/deprecation.py:106: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
            "  warnings.warn(message, mplDeprecation, stacklevel=1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.0011013 Accuracy Last Time Step 0.48\n",
            "Loss 0.99993414 Accuracy Last Time Step 0.54\n",
            "Loss 0.99941933 Accuracy Last Time Step 0.55\n",
            "Loss 0.9995158 Accuracy Last Time Step 0.54\n",
            "Loss 0.99682486 Accuracy Last Time Step 0.44\n",
            "Loss 0.9990572 Accuracy Last Time Step 0.58\n",
            "Loss 0.9985435 Accuracy Last Time Step 0.49\n",
            "Loss 0.99892133 Accuracy Last Time Step 0.47\n",
            "Loss 0.99925613 Accuracy Last Time Step 0.5\n",
            "Loss 0.9997146 Accuracy Last Time Step 0.52\n",
            "Loss 1.0003163 Accuracy Last Time Step 0.43\n",
            "Loss 1.0001831 Accuracy Last Time Step 0.48\n",
            "Loss 0.9980307 Accuracy Last Time Step 0.54\n",
            "Loss 0.9971531 Accuracy Last Time Step 0.55\n",
            "Loss 0.99865746 Accuracy Last Time Step 0.51\n",
            "Loss 0.9995311 Accuracy Last Time Step 0.46\n",
            "Loss 1.0001382 Accuracy Last Time Step 0.5\n",
            "Loss 0.9981355 Accuracy Last Time Step 0.4\n",
            "Loss 0.99930894 Accuracy Last Time Step 0.43\n",
            "Loss 1.0000069 Accuracy Last Time Step 0.52\n",
            "Loss 1.0007659 Accuracy Last Time Step 0.5\n",
            "Loss 1.0000224 Accuracy Last Time Step 0.47\n",
            "Loss 0.9961617 Accuracy Last Time Step 0.59\n",
            "Loss 0.9979144 Accuracy Last Time Step 0.39\n",
            "Loss 0.9987253 Accuracy Last Time Step 0.49\n",
            "Loss 0.9989815 Accuracy Last Time Step 0.5\n",
            "Loss 0.99892825 Accuracy Last Time Step 0.46\n",
            "Loss 0.999402 Accuracy Last Time Step 0.47\n",
            "Loss 1.0004061 Accuracy Last Time Step 0.48\n",
            "Loss 0.99903023 Accuracy Last Time Step 0.57\n",
            "Loss 0.996737 Accuracy Last Time Step 0.5\n",
            "Loss 0.99904233 Accuracy Last Time Step 0.47\n",
            "Loss 0.9990231 Accuracy Last Time Step 0.43\n",
            "Loss 0.9975657 Accuracy Last Time Step 0.44\n",
            "Loss 0.99839735 Accuracy Last Time Step 0.45\n",
            "Loss 1.0004723 Accuracy Last Time Step 0.44\n",
            "Loss 0.9975229 Accuracy Last Time Step 0.52\n",
            "Loss 0.99541223 Accuracy Last Time Step 0.47\n",
            "Loss 0.9975915 Accuracy Last Time Step 0.47\n",
            "Loss 0.9989655 Accuracy Last Time Step 0.61\n",
            "Loss 1.0021354 Accuracy Last Time Step 0.53\n",
            "Loss 0.9988596 Accuracy Last Time Step 0.52\n",
            "Loss 0.99745995 Accuracy Last Time Step 0.5\n",
            "Loss 0.9981169 Accuracy Last Time Step 0.45\n",
            "Loss 0.998926 Accuracy Last Time Step 0.46\n",
            "Loss 1.0000573 Accuracy Last Time Step 0.53\n",
            "Loss 0.9958656 Accuracy Last Time Step 0.47\n",
            "Loss 1.002212 Accuracy Last Time Step 0.47\n",
            "Loss 0.99969995 Accuracy Last Time Step 0.5\n",
            "Loss 0.9956944 Accuracy Last Time Step 0.5\n",
            "Loss 0.99792457 Accuracy Last Time Step 0.52\n",
            "Loss 1.0008335 Accuracy Last Time Step 0.53\n",
            "Loss 0.99767435 Accuracy Last Time Step 0.57\n",
            "Loss 0.99937403 Accuracy Last Time Step 0.47\n",
            "Loss 0.9983695 Accuracy Last Time Step 0.58\n",
            "Loss 1.0005465 Accuracy Last Time Step 0.48\n",
            "Loss 0.99596536 Accuracy Last Time Step 0.48\n",
            "Loss 0.9973795 Accuracy Last Time Step 0.49\n",
            "Loss 0.9993551 Accuracy Last Time Step 0.59\n",
            "Loss 0.99819016 Accuracy Last Time Step 0.48\n",
            "Loss 0.99576724 Accuracy Last Time Step 0.49\n",
            "Loss 0.9974216 Accuracy Last Time Step 0.55\n",
            "Loss 0.9980561 Accuracy Last Time Step 0.47\n",
            "Loss 0.99806136 Accuracy Last Time Step 0.52\n",
            "Loss 0.9959862 Accuracy Last Time Step 0.51\n",
            "Loss 0.9958534 Accuracy Last Time Step 0.47\n",
            "Loss 1.0007749 Accuracy Last Time Step 0.48\n",
            "Loss 0.9980025 Accuracy Last Time Step 0.47\n",
            "Loss 0.99835616 Accuracy Last Time Step 0.43\n",
            "Loss 0.99629575 Accuracy Last Time Step 0.44\n",
            "Loss 0.99991125 Accuracy Last Time Step 0.47\n",
            "Loss 0.99697 Accuracy Last Time Step 0.5\n",
            "Loss 0.9974547 Accuracy Last Time Step 0.56\n",
            "Loss 0.9953009 Accuracy Last Time Step 0.52\n",
            "Loss 0.9997077 Accuracy Last Time Step 0.5\n",
            "Loss 0.9984689 Accuracy Last Time Step 0.48\n",
            "Loss 0.99704856 Accuracy Last Time Step 0.57\n",
            "Loss 0.99881256 Accuracy Last Time Step 0.54\n",
            "Loss 1.0001017 Accuracy Last Time Step 0.46\n",
            "Loss 1.0017478 Accuracy Last Time Step 0.57\n",
            "Loss 0.99930954 Accuracy Last Time Step 0.42\n",
            "Loss 0.99991995 Accuracy Last Time Step 0.43\n",
            "Loss 1.0006182 Accuracy Last Time Step 0.5\n",
            "Loss 0.9969924 Accuracy Last Time Step 0.5\n",
            "Loss 0.9984269 Accuracy Last Time Step 0.48\n",
            "Loss 0.99673796 Accuracy Last Time Step 0.51\n",
            "Loss 0.99515295 Accuracy Last Time Step 0.55\n",
            "Loss 0.99625415 Accuracy Last Time Step 0.46\n",
            "Loss 0.9978562 Accuracy Last Time Step 0.48\n",
            "Loss 0.99655855 Accuracy Last Time Step 0.52\n",
            "Loss 0.9924786 Accuracy Last Time Step 0.55\n",
            "Loss 0.995549 Accuracy Last Time Step 0.47\n",
            "Loss 0.997248 Accuracy Last Time Step 0.52\n",
            "Loss 0.9983375 Accuracy Last Time Step 0.53\n",
            "Loss 0.9943485 Accuracy Last Time Step 0.5\n",
            "Loss 1.0000948 Accuracy Last Time Step 0.46\n",
            "Loss 1.0033742 Accuracy Last Time Step 0.59\n",
            "Loss 1.0005982 Accuracy Last Time Step 0.48\n",
            "Loss 0.996819 Accuracy Last Time Step 0.52\n",
            "Loss 0.99686646 Accuracy Last Time Step 0.42\n",
            "Loss 0.9981757 Accuracy Last Time Step 0.47\n",
            "Loss 0.99573624 Accuracy Last Time Step 0.47\n",
            "Loss 0.9957456 Accuracy Last Time Step 0.55\n",
            "Loss 0.99738497 Accuracy Last Time Step 0.41\n",
            "Loss 0.9969547 Accuracy Last Time Step 0.54\n",
            "Loss 0.9975787 Accuracy Last Time Step 0.45\n",
            "Loss 0.99436545 Accuracy Last Time Step 0.53\n",
            "Loss 0.99333113 Accuracy Last Time Step 0.56\n",
            "Loss 0.9987319 Accuracy Last Time Step 0.57\n",
            "Loss 0.9995376 Accuracy Last Time Step 0.56\n",
            "Loss 0.9905907 Accuracy Last Time Step 0.51\n",
            "Loss 1.0003701 Accuracy Last Time Step 0.52\n",
            "Loss 0.99765295 Accuracy Last Time Step 0.54\n",
            "Loss 0.9953005 Accuracy Last Time Step 0.6\n",
            "Loss 0.9946223 Accuracy Last Time Step 0.45\n",
            "Loss 0.99694574 Accuracy Last Time Step 0.48\n",
            "Loss 0.99431247 Accuracy Last Time Step 0.52\n",
            "Loss 0.99946713 Accuracy Last Time Step 0.55\n",
            "Loss 1.0023702 Accuracy Last Time Step 0.42\n",
            "Loss 0.9934337 Accuracy Last Time Step 0.5\n",
            "Loss 0.9984828 Accuracy Last Time Step 0.54\n",
            "Loss 0.99967384 Accuracy Last Time Step 0.39\n",
            "Loss 0.99626565 Accuracy Last Time Step 0.47\n",
            "Loss 1.0018193 Accuracy Last Time Step 0.46\n",
            "Loss 0.9979569 Accuracy Last Time Step 0.48\n",
            "Loss 0.9990641 Accuracy Last Time Step 0.43\n",
            "Loss 0.99126875 Accuracy Last Time Step 0.46\n",
            "Loss 0.99531204 Accuracy Last Time Step 0.45\n",
            "Loss 1.000432 Accuracy Last Time Step 0.5\n",
            "Loss 0.9956422 Accuracy Last Time Step 0.54\n",
            "Loss 1.0002916 Accuracy Last Time Step 0.42\n",
            "Loss 1.0000468 Accuracy Last Time Step 0.51\n",
            "Loss 0.99725753 Accuracy Last Time Step 0.48\n",
            "Loss 0.9942791 Accuracy Last Time Step 0.57\n",
            "Loss 0.99445045 Accuracy Last Time Step 0.5\n",
            "Loss 1.0002935 Accuracy Last Time Step 0.48\n",
            "Loss 0.9973622 Accuracy Last Time Step 0.46\n",
            "Loss 0.9938286 Accuracy Last Time Step 0.54\n",
            "Loss 0.9894978 Accuracy Last Time Step 0.52\n",
            "Loss 0.9914919 Accuracy Last Time Step 0.51\n",
            "Loss 0.9963074 Accuracy Last Time Step 0.46\n",
            "Loss 0.99695206 Accuracy Last Time Step 0.57\n",
            "Loss 0.9901524 Accuracy Last Time Step 0.57\n",
            "Loss 0.99201745 Accuracy Last Time Step 0.57\n",
            "Loss 0.99221146 Accuracy Last Time Step 0.47\n",
            "Loss 0.995822 Accuracy Last Time Step 0.5\n",
            "Loss 0.99688613 Accuracy Last Time Step 0.51\n",
            "Loss 0.99052644 Accuracy Last Time Step 0.52\n",
            "Loss 0.9906515 Accuracy Last Time Step 0.6\n",
            "Loss 0.9980237 Accuracy Last Time Step 0.47\n",
            "Loss 0.99430156 Accuracy Last Time Step 0.58\n",
            "Loss 1.0062281 Accuracy Last Time Step 0.53\n",
            "Loss 1.0002885 Accuracy Last Time Step 0.49\n",
            "Loss 0.9951801 Accuracy Last Time Step 0.5\n",
            "Loss 0.9946712 Accuracy Last Time Step 0.45\n",
            "Loss 0.9918123 Accuracy Last Time Step 0.58\n",
            "Loss 1.0027182 Accuracy Last Time Step 0.49\n",
            "Loss 0.9919231 Accuracy Last Time Step 0.51\n",
            "Loss 1.0012009 Accuracy Last Time Step 0.46\n",
            "Loss 0.99233687 Accuracy Last Time Step 0.48\n",
            "Loss 0.99420846 Accuracy Last Time Step 0.44\n",
            "Loss 0.9936006 Accuracy Last Time Step 0.39\n",
            "Loss 0.99605453 Accuracy Last Time Step 0.46\n",
            "Loss 0.99116194 Accuracy Last Time Step 0.46\n",
            "Loss 0.9915504 Accuracy Last Time Step 0.42\n",
            "Loss 0.992602 Accuracy Last Time Step 0.5\n",
            "Loss 0.9968704 Accuracy Last Time Step 0.46\n",
            "Loss 1.0000514 Accuracy Last Time Step 0.44\n",
            "Loss 0.9957324 Accuracy Last Time Step 0.49\n",
            "Loss 0.99215215 Accuracy Last Time Step 0.5\n",
            "Loss 0.99365747 Accuracy Last Time Step 0.51\n",
            "Loss 0.99186814 Accuracy Last Time Step 0.4\n",
            "Loss 0.99542564 Accuracy Last Time Step 0.56\n",
            "Loss 0.98709226 Accuracy Last Time Step 0.43\n",
            "Loss 0.98757005 Accuracy Last Time Step 0.54\n",
            "Loss 0.9936033 Accuracy Last Time Step 0.46\n",
            "Loss 0.990881 Accuracy Last Time Step 0.46\n",
            "Loss 1.000912 Accuracy Last Time Step 0.49\n",
            "Loss 0.99483836 Accuracy Last Time Step 0.43\n",
            "Loss 0.99670905 Accuracy Last Time Step 0.47\n",
            "Loss 0.9885564 Accuracy Last Time Step 0.51\n",
            "Loss 0.9944912 Accuracy Last Time Step 0.55\n",
            "Loss 0.9962278 Accuracy Last Time Step 0.52\n",
            "Loss 0.99697286 Accuracy Last Time Step 0.52\n",
            "Loss 0.99276644 Accuracy Last Time Step 0.46\n",
            "Loss 1.0051584 Accuracy Last Time Step 0.55\n",
            "Loss 0.9937779 Accuracy Last Time Step 0.5\n",
            "Loss 0.99476886 Accuracy Last Time Step 0.48\n",
            "Loss 0.9914039 Accuracy Last Time Step 0.57\n",
            "Loss 0.9953549 Accuracy Last Time Step 0.41\n",
            "Loss 0.9887785 Accuracy Last Time Step 0.48\n",
            "Loss 0.9958603 Accuracy Last Time Step 0.52\n",
            "Loss 0.9910674 Accuracy Last Time Step 0.63\n",
            "Loss 0.98692894 Accuracy Last Time Step 0.54\n",
            "Loss 0.9942794 Accuracy Last Time Step 0.52\n",
            "Loss 0.98799914 Accuracy Last Time Step 0.49\n",
            "Loss 0.9964823 Accuracy Last Time Step 0.45\n",
            "Loss 0.9926947 Accuracy Last Time Step 0.47\n",
            "Loss 0.9932678 Accuracy Last Time Step 0.42\n",
            "Loss 0.9932239 Accuracy Last Time Step 0.48\n",
            "Loss 0.9903414 Accuracy Last Time Step 0.56\n",
            "Loss 0.9991141 Accuracy Last Time Step 0.46\n",
            "Loss 0.99533945 Accuracy Last Time Step 0.49\n",
            "Loss 0.98954237 Accuracy Last Time Step 0.58\n",
            "Loss 1.0036601 Accuracy Last Time Step 0.47\n",
            "Loss 0.9863431 Accuracy Last Time Step 0.43\n",
            "Loss 0.9958904 Accuracy Last Time Step 0.4\n",
            "Loss 0.99184746 Accuracy Last Time Step 0.53\n",
            "Loss 0.9947657 Accuracy Last Time Step 0.48\n",
            "Loss 0.9907282 Accuracy Last Time Step 0.54\n",
            "Loss 0.9947306 Accuracy Last Time Step 0.47\n",
            "Loss 0.99740446 Accuracy Last Time Step 0.5\n",
            "Loss 0.98934036 Accuracy Last Time Step 0.48\n",
            "Loss 1.0002694 Accuracy Last Time Step 0.51\n",
            "Loss 1.0006438 Accuracy Last Time Step 0.53\n",
            "Loss 0.9924261 Accuracy Last Time Step 0.54\n",
            "Loss 0.993557 Accuracy Last Time Step 0.5\n",
            "Loss 0.99133927 Accuracy Last Time Step 0.45\n",
            "Loss 0.99549127 Accuracy Last Time Step 0.57\n",
            "Loss 0.99167705 Accuracy Last Time Step 0.51\n",
            "Loss 0.99951464 Accuracy Last Time Step 0.39\n",
            "Loss 1.0027684 Accuracy Last Time Step 0.49\n",
            "Loss 0.9923739 Accuracy Last Time Step 0.55\n",
            "Loss 0.9917125 Accuracy Last Time Step 0.44\n",
            "Loss 0.9850342 Accuracy Last Time Step 0.56\n",
            "Loss 0.9812878 Accuracy Last Time Step 0.45\n",
            "Loss 0.98175865 Accuracy Last Time Step 0.53\n",
            "Loss 0.98995024 Accuracy Last Time Step 0.48\n",
            "Loss 0.9849406 Accuracy Last Time Step 0.59\n",
            "Loss 0.99716073 Accuracy Last Time Step 0.53\n",
            "Loss 1.0010736 Accuracy Last Time Step 0.48\n",
            "Loss 0.9926241 Accuracy Last Time Step 0.49\n",
            "Loss 0.9928041 Accuracy Last Time Step 0.48\n",
            "Loss 0.99135405 Accuracy Last Time Step 0.51\n",
            "Loss 0.98914266 Accuracy Last Time Step 0.58\n",
            "Loss 0.992672 Accuracy Last Time Step 0.58\n",
            "Loss 0.9868703 Accuracy Last Time Step 0.52\n",
            "Loss 0.99387556 Accuracy Last Time Step 0.58\n",
            "Loss 1.0000618 Accuracy Last Time Step 0.52\n",
            "Loss 0.9948133 Accuracy Last Time Step 0.51\n",
            "Loss 0.9962046 Accuracy Last Time Step 0.58\n",
            "Loss 0.9916976 Accuracy Last Time Step 0.51\n",
            "Loss 0.98644423 Accuracy Last Time Step 0.53\n",
            "Loss 0.9916768 Accuracy Last Time Step 0.51\n",
            "Loss 0.9851709 Accuracy Last Time Step 0.55\n",
            "Loss 0.989796 Accuracy Last Time Step 0.5\n",
            "Loss 0.9889082 Accuracy Last Time Step 0.52\n",
            "Loss 0.98357916 Accuracy Last Time Step 0.53\n",
            "Loss 0.9905966 Accuracy Last Time Step 0.5\n",
            "Loss 0.98910224 Accuracy Last Time Step 0.48\n",
            "Loss 0.98567766 Accuracy Last Time Step 0.58\n",
            "Loss 0.98368037 Accuracy Last Time Step 0.44\n",
            "Loss 0.9961439 Accuracy Last Time Step 0.56\n",
            "Loss 0.98951006 Accuracy Last Time Step 0.51\n",
            "Loss 0.9926997 Accuracy Last Time Step 0.54\n",
            "Loss 0.9870093 Accuracy Last Time Step 0.55\n",
            "Loss 0.9846679 Accuracy Last Time Step 0.51\n",
            "Loss 1.0040878 Accuracy Last Time Step 0.48\n",
            "Loss 0.97830725 Accuracy Last Time Step 0.49\n",
            "Loss 1.010389 Accuracy Last Time Step 0.51\n",
            "Loss 0.9861948 Accuracy Last Time Step 0.53\n",
            "Loss 0.99331236 Accuracy Last Time Step 0.56\n",
            "Loss 0.98513204 Accuracy Last Time Step 0.46\n",
            "Loss 0.97570384 Accuracy Last Time Step 0.44\n",
            "Loss 0.9919431 Accuracy Last Time Step 0.43\n",
            "Loss 0.9969786 Accuracy Last Time Step 0.49\n",
            "Loss 0.97367024 Accuracy Last Time Step 0.58\n",
            "Loss 0.99002284 Accuracy Last Time Step 0.48\n",
            "Loss 0.9961862 Accuracy Last Time Step 0.39\n",
            "Loss 0.984198 Accuracy Last Time Step 0.5\n",
            "Loss 0.9977392 Accuracy Last Time Step 0.54\n",
            "Loss 0.99455476 Accuracy Last Time Step 0.42\n",
            "Loss 0.9897319 Accuracy Last Time Step 0.49\n",
            "Loss 1.0012547 Accuracy Last Time Step 0.46\n",
            "Loss 0.97903466 Accuracy Last Time Step 0.51\n",
            "Loss 0.9949333 Accuracy Last Time Step 0.57\n",
            "Loss 0.99343467 Accuracy Last Time Step 0.49\n",
            "Loss 0.9925206 Accuracy Last Time Step 0.38\n",
            "Loss 0.994888 Accuracy Last Time Step 0.57\n",
            "Loss 0.9852153 Accuracy Last Time Step 0.56\n",
            "Loss 0.9909433 Accuracy Last Time Step 0.44\n",
            "Loss 0.9977134 Accuracy Last Time Step 0.57\n",
            "Loss 1.0030925 Accuracy Last Time Step 0.42\n",
            "Loss 0.99070555 Accuracy Last Time Step 0.49\n",
            "Loss 0.9995779 Accuracy Last Time Step 0.41\n",
            "Loss 0.9876076 Accuracy Last Time Step 0.53\n",
            "Loss 0.97876036 Accuracy Last Time Step 0.42\n",
            "Loss 0.9954379 Accuracy Last Time Step 0.49\n",
            "Loss 0.9862932 Accuracy Last Time Step 0.47\n",
            "Loss 0.9724182 Accuracy Last Time Step 0.63\n",
            "Loss 0.99009156 Accuracy Last Time Step 0.54\n",
            "Loss 1.0092016 Accuracy Last Time Step 0.49\n",
            "Loss 0.97115225 Accuracy Last Time Step 0.53\n",
            "Loss 1.0003586 Accuracy Last Time Step 0.5\n",
            "Loss 1.0000012 Accuracy Last Time Step 0.43\n",
            "Loss 0.9879022 Accuracy Last Time Step 0.51\n",
            "Loss 0.98930746 Accuracy Last Time Step 0.49\n",
            "Loss 1.0003386 Accuracy Last Time Step 0.48\n",
            "Loss 0.9781503 Accuracy Last Time Step 0.52\n",
            "Loss 0.98871064 Accuracy Last Time Step 0.43\n",
            "Loss 0.9731522 Accuracy Last Time Step 0.51\n",
            "Loss 0.98390716 Accuracy Last Time Step 0.63\n",
            "Loss 0.9979363 Accuracy Last Time Step 0.51\n",
            "Loss 0.9875925 Accuracy Last Time Step 0.52\n",
            "Loss 0.9714132 Accuracy Last Time Step 0.51\n",
            "Loss 0.99627066 Accuracy Last Time Step 0.52\n",
            "Loss 0.9701291 Accuracy Last Time Step 0.44\n",
            "Loss 0.98765785 Accuracy Last Time Step 0.47\n",
            "Loss 0.98217726 Accuracy Last Time Step 0.44\n",
            "Loss 0.9921741 Accuracy Last Time Step 0.54\n",
            "Loss 0.9975967 Accuracy Last Time Step 0.56\n",
            "Loss 0.983865 Accuracy Last Time Step 0.57\n",
            "Loss 0.96538836 Accuracy Last Time Step 0.43\n",
            "Loss 0.9883865 Accuracy Last Time Step 0.56\n",
            "Loss 1.0075593 Accuracy Last Time Step 0.44\n",
            "Loss 0.9671287 Accuracy Last Time Step 0.45\n",
            "Loss 0.9758442 Accuracy Last Time Step 0.6\n",
            "Loss 0.98292357 Accuracy Last Time Step 0.44\n",
            "Loss 0.9850365 Accuracy Last Time Step 0.51\n",
            "Loss 0.95073485 Accuracy Last Time Step 0.43\n",
            "Loss 1.004735 Accuracy Last Time Step 0.46\n",
            "Loss 0.99625146 Accuracy Last Time Step 0.49\n",
            "Loss 0.98794883 Accuracy Last Time Step 0.55\n",
            "Loss 0.98105973 Accuracy Last Time Step 0.4\n",
            "Loss 0.99160475 Accuracy Last Time Step 0.48\n",
            "Loss 0.9804633 Accuracy Last Time Step 0.42\n",
            "Loss 1.001568 Accuracy Last Time Step 0.53\n",
            "Loss 0.976257 Accuracy Last Time Step 0.47\n",
            "Loss 0.9752766 Accuracy Last Time Step 0.57\n",
            "Loss 0.98934484 Accuracy Last Time Step 0.51\n",
            "Loss 0.98548585 Accuracy Last Time Step 0.54\n",
            "Loss 0.9926799 Accuracy Last Time Step 0.44\n",
            "Loss 0.97944534 Accuracy Last Time Step 0.44\n",
            "Loss 0.9860692 Accuracy Last Time Step 0.57\n",
            "Loss 0.9641065 Accuracy Last Time Step 0.52\n",
            "Loss 0.9990017 Accuracy Last Time Step 0.46\n",
            "Loss 0.98886466 Accuracy Last Time Step 0.57\n",
            "Loss 0.9700792 Accuracy Last Time Step 0.46\n",
            "Loss 0.9827012 Accuracy Last Time Step 0.51\n",
            "Loss 0.9949665 Accuracy Last Time Step 0.59\n",
            "Loss 0.991711 Accuracy Last Time Step 0.48\n",
            "Loss 0.972174 Accuracy Last Time Step 0.56\n",
            "Loss 0.9723894 Accuracy Last Time Step 0.49\n",
            "Loss 1.004714 Accuracy Last Time Step 0.56\n",
            "Loss 0.9959099 Accuracy Last Time Step 0.48\n",
            "Loss 1.0155488 Accuracy Last Time Step 0.42\n",
            "Loss 0.9711935 Accuracy Last Time Step 0.51\n",
            "Loss 1.014006 Accuracy Last Time Step 0.44\n",
            "Loss 0.97987276 Accuracy Last Time Step 0.53\n",
            "Loss 0.996534 Accuracy Last Time Step 0.49\n",
            "Loss 0.9759317 Accuracy Last Time Step 0.55\n",
            "Loss 1.0097127 Accuracy Last Time Step 0.51\n",
            "Loss 0.9957386 Accuracy Last Time Step 0.5\n",
            "Loss 0.9619283 Accuracy Last Time Step 0.54\n",
            "Loss 0.95520097 Accuracy Last Time Step 0.59\n",
            "Loss 0.98569864 Accuracy Last Time Step 0.54\n",
            "Loss 1.0064377 Accuracy Last Time Step 0.42\n",
            "Loss 0.98200643 Accuracy Last Time Step 0.56\n",
            "Loss 0.974641 Accuracy Last Time Step 0.49\n",
            "Loss 0.96828103 Accuracy Last Time Step 0.49\n",
            "Loss 0.99563825 Accuracy Last Time Step 0.56\n",
            "Loss 0.9786805 Accuracy Last Time Step 0.44\n",
            "Loss 0.98566484 Accuracy Last Time Step 0.42\n",
            "Loss 0.9860045 Accuracy Last Time Step 0.51\n",
            "Loss 0.98427933 Accuracy Last Time Step 0.48\n",
            "Loss 0.98168594 Accuracy Last Time Step 0.46\n",
            "Loss 0.96296483 Accuracy Last Time Step 0.37\n",
            "Loss 1.0015942 Accuracy Last Time Step 0.5\n",
            "Loss 0.992316 Accuracy Last Time Step 0.45\n",
            "Loss 0.9902665 Accuracy Last Time Step 0.47\n",
            "Loss 0.97417116 Accuracy Last Time Step 0.45\n",
            "Loss 1.0031846 Accuracy Last Time Step 0.6\n",
            "Loss 0.97042185 Accuracy Last Time Step 0.49\n",
            "Loss 0.979956 Accuracy Last Time Step 0.52\n",
            "Loss 0.98332906 Accuracy Last Time Step 0.55\n",
            "Loss 0.9823913 Accuracy Last Time Step 0.48\n",
            "Loss 0.95955896 Accuracy Last Time Step 0.57\n",
            "Loss 0.9685497 Accuracy Last Time Step 0.56\n",
            "Loss 0.96818906 Accuracy Last Time Step 0.6\n",
            "Loss 0.9872995 Accuracy Last Time Step 0.45\n",
            "Loss 0.97363657 Accuracy Last Time Step 0.48\n",
            "Loss 0.99001414 Accuracy Last Time Step 0.41\n",
            "Loss 0.95665467 Accuracy Last Time Step 0.54\n",
            "Loss 0.98135734 Accuracy Last Time Step 0.42\n",
            "Loss 0.9816797 Accuracy Last Time Step 0.54\n",
            "Loss 0.9764513 Accuracy Last Time Step 0.48\n",
            "Loss 0.97515273 Accuracy Last Time Step 0.53\n",
            "Loss 0.9776306 Accuracy Last Time Step 0.49\n",
            "Loss 0.98246217 Accuracy Last Time Step 0.49\n",
            "Loss 0.9850334 Accuracy Last Time Step 0.51\n",
            "Loss 0.9888937 Accuracy Last Time Step 0.57\n",
            "Loss 1.0055318 Accuracy Last Time Step 0.56\n",
            "Loss 0.98849297 Accuracy Last Time Step 0.49\n",
            "Loss 0.9936572 Accuracy Last Time Step 0.33\n",
            "Loss 0.98026955 Accuracy Last Time Step 0.49\n",
            "Loss 0.97324914 Accuracy Last Time Step 0.53\n",
            "Loss 0.9843531 Accuracy Last Time Step 0.45\n",
            "Loss 0.9636268 Accuracy Last Time Step 0.47\n",
            "Loss 0.9980542 Accuracy Last Time Step 0.52\n",
            "Loss 0.99045503 Accuracy Last Time Step 0.44\n",
            "Loss 0.99261826 Accuracy Last Time Step 0.45\n",
            "Loss 0.99632776 Accuracy Last Time Step 0.49\n",
            "Loss 0.97168994 Accuracy Last Time Step 0.49\n",
            "Loss 1.0032212 Accuracy Last Time Step 0.41\n",
            "Loss 0.98915535 Accuracy Last Time Step 0.56\n",
            "Loss 0.98286414 Accuracy Last Time Step 0.44\n",
            "Loss 0.9539459 Accuracy Last Time Step 0.54\n",
            "Loss 0.9718884 Accuracy Last Time Step 0.53\n",
            "Loss 0.96081674 Accuracy Last Time Step 0.48\n",
            "Loss 0.96920556 Accuracy Last Time Step 0.46\n",
            "Loss 0.99691945 Accuracy Last Time Step 0.46\n",
            "Loss 0.9857018 Accuracy Last Time Step 0.47\n",
            "Loss 0.9509127 Accuracy Last Time Step 0.51\n",
            "Loss 0.97966105 Accuracy Last Time Step 0.49\n",
            "Loss 0.96384233 Accuracy Last Time Step 0.6\n",
            "Loss 0.97094136 Accuracy Last Time Step 0.57\n",
            "Loss 0.98486847 Accuracy Last Time Step 0.55\n",
            "Loss 0.99203455 Accuracy Last Time Step 0.49\n",
            "Loss 0.97858405 Accuracy Last Time Step 0.42\n",
            "Loss 0.99376494 Accuracy Last Time Step 0.52\n",
            "Loss 0.9746834 Accuracy Last Time Step 0.45\n",
            "Loss 0.984759 Accuracy Last Time Step 0.5\n",
            "Loss 1.0049424 Accuracy Last Time Step 0.49\n",
            "Loss 0.9914641 Accuracy Last Time Step 0.52\n",
            "Loss 0.99396795 Accuracy Last Time Step 0.53\n",
            "Loss 1.0093176 Accuracy Last Time Step 0.49\n",
            "Loss 0.99304926 Accuracy Last Time Step 0.5\n",
            "Loss 0.9795142 Accuracy Last Time Step 0.52\n",
            "Loss 0.96286315 Accuracy Last Time Step 0.5\n",
            "Loss 0.97916675 Accuracy Last Time Step 0.52\n",
            "Loss 0.9664141 Accuracy Last Time Step 0.51\n",
            "Loss 1.0053867 Accuracy Last Time Step 0.47\n",
            "Loss 0.98161733 Accuracy Last Time Step 0.57\n",
            "Loss 0.9708028 Accuracy Last Time Step 0.48\n",
            "Loss 0.9849903 Accuracy Last Time Step 0.53\n",
            "Loss 0.98715514 Accuracy Last Time Step 0.5\n",
            "Loss 0.9818831 Accuracy Last Time Step 0.4\n",
            "Loss 0.96331865 Accuracy Last Time Step 0.59\n",
            "Loss 0.9817358 Accuracy Last Time Step 0.48\n",
            "Loss 0.9861567 Accuracy Last Time Step 0.6\n",
            "Loss 1.002675 Accuracy Last Time Step 0.44\n",
            "Loss 0.9523452 Accuracy Last Time Step 0.51\n",
            "Loss 0.97823316 Accuracy Last Time Step 0.57\n",
            "Loss 0.99482286 Accuracy Last Time Step 0.48\n",
            "Loss 0.9733074 Accuracy Last Time Step 0.53\n",
            "Loss 0.9733006 Accuracy Last Time Step 0.5\n",
            "Loss 1.003801 Accuracy Last Time Step 0.49\n",
            "Loss 0.98664683 Accuracy Last Time Step 0.52\n",
            "Loss 0.9777529 Accuracy Last Time Step 0.4\n",
            "Loss 0.9981279 Accuracy Last Time Step 0.56\n",
            "Loss 0.9853189 Accuracy Last Time Step 0.56\n",
            "Loss 0.9833453 Accuracy Last Time Step 0.49\n",
            "Loss 0.9968989 Accuracy Last Time Step 0.45\n",
            "Loss 1.0066448 Accuracy Last Time Step 0.49\n",
            "Loss 0.9754314 Accuracy Last Time Step 0.48\n",
            "Loss 0.9772394 Accuracy Last Time Step 0.47\n",
            "Loss 0.99378276 Accuracy Last Time Step 0.44\n",
            "Loss 0.99318784 Accuracy Last Time Step 0.49\n",
            "Loss 0.9701958 Accuracy Last Time Step 0.49\n",
            "Loss 0.9703887 Accuracy Last Time Step 0.42\n",
            "Loss 0.96759367 Accuracy Last Time Step 0.47\n",
            "Loss 0.97960454 Accuracy Last Time Step 0.55\n",
            "Loss 0.969189 Accuracy Last Time Step 0.42\n",
            "Loss 0.9831854 Accuracy Last Time Step 0.54\n",
            "Loss 0.98869634 Accuracy Last Time Step 0.51\n",
            "Loss 0.97727823 Accuracy Last Time Step 0.53\n",
            "Loss 0.9759045 Accuracy Last Time Step 0.48\n",
            "Loss 0.98406446 Accuracy Last Time Step 0.59\n",
            "Loss 0.97631395 Accuracy Last Time Step 0.61\n",
            "Loss 0.99764204 Accuracy Last Time Step 0.42\n",
            "Loss 0.9872151 Accuracy Last Time Step 0.49\n",
            "Loss 0.9760375 Accuracy Last Time Step 0.55\n",
            "Loss 0.97406125 Accuracy Last Time Step 0.51\n",
            "Loss 0.97426283 Accuracy Last Time Step 0.52\n",
            "Loss 0.9644585 Accuracy Last Time Step 0.56\n",
            "Loss 0.9973181 Accuracy Last Time Step 0.45\n",
            "Loss 0.9834949 Accuracy Last Time Step 0.56\n",
            "Loss 0.9964959 Accuracy Last Time Step 0.38\n",
            "Loss 0.9865535 Accuracy Last Time Step 0.45\n",
            "Loss 0.99660087 Accuracy Last Time Step 0.53\n",
            "Loss 0.98462194 Accuracy Last Time Step 0.48\n",
            "Loss 0.97308105 Accuracy Last Time Step 0.53\n",
            "Loss 0.986714 Accuracy Last Time Step 0.53\n",
            "Loss 0.9590422 Accuracy Last Time Step 0.61\n",
            "Loss 0.98767847 Accuracy Last Time Step 0.55\n",
            "Loss 0.9769665 Accuracy Last Time Step 0.52\n",
            "Loss 0.9797684 Accuracy Last Time Step 0.52\n",
            "Loss 1.0020908 Accuracy Last Time Step 0.54\n",
            "Loss 0.97449803 Accuracy Last Time Step 0.45\n",
            "Loss 0.9780627 Accuracy Last Time Step 0.52\n",
            "Loss 0.9752786 Accuracy Last Time Step 0.48\n",
            "Loss 0.9818012 Accuracy Last Time Step 0.62\n",
            "Loss 0.97266096 Accuracy Last Time Step 0.44\n",
            "Loss 0.95673525 Accuracy Last Time Step 0.52\n",
            "Loss 1.0110737 Accuracy Last Time Step 0.54\n",
            "Loss 0.98506683 Accuracy Last Time Step 0.52\n",
            "Loss 0.98963004 Accuracy Last Time Step 0.5\n",
            "Loss 0.9756388 Accuracy Last Time Step 0.44\n",
            "Loss 0.9556018 Accuracy Last Time Step 0.51\n",
            "Loss 0.99821055 Accuracy Last Time Step 0.43\n",
            "Loss 0.98194593 Accuracy Last Time Step 0.52\n",
            "Loss 0.9646141 Accuracy Last Time Step 0.52\n",
            "Loss 0.96564674 Accuracy Last Time Step 0.6\n",
            "Loss 0.99686944 Accuracy Last Time Step 0.49\n",
            "Loss 0.9633167 Accuracy Last Time Step 0.49\n",
            "Loss 0.962123 Accuracy Last Time Step 0.48\n",
            "Loss 0.9619887 Accuracy Last Time Step 0.56\n",
            "Loss 0.9912597 Accuracy Last Time Step 0.58\n",
            "Loss 0.9681197 Accuracy Last Time Step 0.59\n",
            "Loss 0.9623169 Accuracy Last Time Step 0.65\n",
            "Loss 0.9790585 Accuracy Last Time Step 0.51\n",
            "Loss 0.9690505 Accuracy Last Time Step 0.51\n",
            "Loss 0.96178186 Accuracy Last Time Step 0.52\n",
            "Loss 0.98108435 Accuracy Last Time Step 0.55\n",
            "Loss 0.9670936 Accuracy Last Time Step 0.42\n",
            "Loss 0.95922685 Accuracy Last Time Step 0.44\n",
            "Loss 0.9609449 Accuracy Last Time Step 0.58\n",
            "Loss 0.95931894 Accuracy Last Time Step 0.49\n",
            "Loss 0.9467275 Accuracy Last Time Step 0.53\n",
            "Loss 0.9849614 Accuracy Last Time Step 0.48\n",
            "Loss 0.9775856 Accuracy Last Time Step 0.48\n",
            "Loss 0.98468727 Accuracy Last Time Step 0.45\n",
            "Loss 0.97505623 Accuracy Last Time Step 0.51\n",
            "Loss 0.9419342 Accuracy Last Time Step 0.51\n",
            "Loss 0.9904824 Accuracy Last Time Step 0.51\n",
            "Loss 0.95429903 Accuracy Last Time Step 0.5\n",
            "Loss 0.9484229 Accuracy Last Time Step 0.53\n",
            "Loss 0.9754417 Accuracy Last Time Step 0.54\n",
            "Loss 0.9686234 Accuracy Last Time Step 0.54\n",
            "Loss 0.97721756 Accuracy Last Time Step 0.55\n",
            "Loss 1.001005 Accuracy Last Time Step 0.54\n",
            "Loss 0.97479707 Accuracy Last Time Step 0.5\n",
            "Loss 0.960149 Accuracy Last Time Step 0.59\n",
            "Loss 0.9571408 Accuracy Last Time Step 0.49\n",
            "Loss 0.9614149 Accuracy Last Time Step 0.52\n",
            "Loss 0.96821284 Accuracy Last Time Step 0.58\n",
            "Loss 0.967907 Accuracy Last Time Step 0.56\n",
            "Loss 0.96596414 Accuracy Last Time Step 0.55\n",
            "Loss 0.9856031 Accuracy Last Time Step 0.5\n",
            "Loss 0.96524775 Accuracy Last Time Step 0.59\n",
            "Loss 0.9679936 Accuracy Last Time Step 0.5\n",
            "Loss 0.96210563 Accuracy Last Time Step 0.45\n",
            "Loss 0.94088966 Accuracy Last Time Step 0.56\n",
            "Loss 0.95994544 Accuracy Last Time Step 0.44\n",
            "Loss 0.90428436 Accuracy Last Time Step 0.45\n",
            "Loss 0.67333245 Accuracy Last Time Step 0.66\n",
            "Loss 828.9921 Accuracy Last Time Step 0.51\n",
            "Loss inf Accuracy Last Time Step 0.55\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n",
            "Loss nan Accuracy Last Time Step 0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFKCAYAAADITfxaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQP4/dxDV6b5Ufa8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fef53f7e400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUWxSYI0-Wix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}