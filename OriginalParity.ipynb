{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OriginalParity.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sosmany1/RNN_Parity-Problem/blob/master/OriginalParity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLj3Pgl_-Eul",
        "colab_type": "code",
        "outputId": "a33a9aa2-60b5-44fa-d239-d2247dbd0bce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import math\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n",
        "\n",
        "def Affine(name_scope,input_tensor,out_channels, relu=True):\n",
        "    input_shape = input_tensor.get_shape().as_list()\n",
        "    input_channels = input_shape[-1]\n",
        "    with tf.name_scope(name_scope):\n",
        "        weights = tf.Variable(tf.truncated_normal([input_channels, out_channels],\n",
        "                                                  stddev=1.0 / math.sqrt(float(input_channels))),\n",
        "                              name='weights')\n",
        "        biases = tf.Variable(tf.zeros([out_channels]),name='biases')\n",
        "        h = tf.matmul(input_tensor, weights) + biases\n",
        "        if relu: return tf.nn.relu(h)\n",
        "        else: return h\n",
        "\n",
        "def get_batch(bs,len_subset,N):\n",
        "    X = 1.0-2*(np.random.randn(bs,N) < 0).astype(np.float32)\n",
        "    relevant_X = X[:,:len_subset] # Assume that v^* has all its 1's at the prefix\n",
        "    if len_subset==1: relevant_X = relevant_X[:,np.newaxis]\n",
        "    Y = np.prod(relevant_X, axis=1)[:,np.newaxis]\n",
        "    return X,Y\n",
        "\n",
        "def run_training(args):\n",
        "    print('Parity d=%d'%(args.d))\n",
        "    len_subset = np.sum(np.random.randn(args.d)>0) if args.subset_size < 0 else args.subset_size\n",
        "    with tf.Graph().as_default():\n",
        "        session = tf.Session()\n",
        "        # These will be inserted as single images\n",
        "        X_placeholder = tf.placeholder(tf.float32, shape=(None,args.d))\n",
        "        Y_placeholder = tf.placeholder(tf.float32, shape=(None,1))\n",
        "        \n",
        "        p1 = Affine('p1', X_placeholder, 10*args.d, relu=True)\n",
        "        score = Affine('score', p1, 1, relu=False)\n",
        "        # Hinge loss\n",
        "        loss = tf.reduce_mean(tf.nn.relu(1.0 - Y_placeholder*score))\n",
        "        \n",
        "        accuracy = tf.reduce_mean(tf.cast(Y_placeholder*score>0,tf.float32))\n",
        "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
        "        train_op = optimizer.minimize(loss)\n",
        "        \n",
        "        session.run(tf.initialize_all_variables())\n",
        "        for step in xrange(args.num_iters):\n",
        "            X,Y = get_batch(args.batch_size,len_subset,args.d)\n",
        "            _ = session.run(train_op,feed_dict={X_placeholder: X, Y_placeholder: Y})\n",
        "            if (step % args.print_freq == 0) or step+1 == args.num_iters:\n",
        "                X,Y = get_batch(500,len_subset,args.d)\n",
        "                fd = {X_placeholder: X, Y_placeholder: Y}\n",
        "                print('\\nIteration %d' % (step))\n",
        "                loss_,accuracy_ = session.run([loss,accuracy],feed_dict=fd)\n",
        "                print('Iteration %d loss %.4f accuracy %.4f'%(step,loss_,accuracy_))\n",
        "                \n",
        "def main(args):\n",
        "    run_training(args)\n",
        "\n",
        "def get_command_line_args():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--d\", default=100, type=int, help='input dimension')\n",
        "    parser.add_argument(\"--num_iters\", default=50000, type=int, help='number of iterations')\n",
        "    parser.add_argument(\"--print_freq\", default=100, type=int, help='print frequency')\n",
        "    parser.add_argument(\"--learning_rate\", default=0.01, type=float, help='learning rate')\n",
        "    parser.add_argument(\"--batch_size\", default=128, type=int, help='batch size')\n",
        "    parser.add_argument(\"--subset_size\", default=-1, type=int, help='size of subset for parity (explicitly, \\\n",
        "                                                                        sum(v^*==1), see paper section 2.1 for notation). \\\n",
        "                                                                        Negative value will result in random.')\n",
        "    args = parser.parse_args()\n",
        "    return args\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main(get_command_line_args())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--d D] [--num_iters NUM_ITERS]\n",
            "                             [--print_freq PRINT_FREQ]\n",
            "                             [--learning_rate LEARNING_RATE]\n",
            "                             [--batch_size BATCH_SIZE]\n",
            "                             [--subset_size SUBSET_SIZE]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-cffd7698-5abb-4d22-94b9-0c7828fff055.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}